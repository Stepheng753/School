\documentclass[12pt]{article}
\usepackage[margin = 1in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{enumitem}
\usepackage{url}

\begin{document}
	
	\begin{center}
		\textbf{Midterm 1} \\
		\textbf{Numerical Matrix Analysis} \\
		\textbf{Math 543} \\
		\textbf{Stephen Giang} \\
	\end{center}

\noindent \textbf{Problem 1: }
	\begin{enumerate}[label = (\alph*)]
		\item For the function $f : X \rightarrow Y$, define the relative condition number $\kappa(x)$ 
		\\ \\
		Let $x \in X$ and $y \in Y$, such that $f(x) = y$
		$$
		\kappa(x) = \sup \limits_{\delta x} \left[\left.\frac{||\delta f||}{||f(x) ||} \right/ \frac{||\delta x||}{||x||}\right]
		$$
		\\ \\
		\item 
		\begin{enumerate}[label = (\roman*)]
			\item What is the smallest (in magnitude) real perturbation $\epsilon_{\mathbb{R}} \in \mathbb{R}\backslash\{0\}$?
			\\ \\ 
			Because there does not exist a smallest positive number in the set of $\mathbb{R}\backslash\{0\}$, the following does not exist. 
			\\ \\
			
			\item What is the smallest (in magnitude) integer perturbation $\epsilon_{\mathbb{Z}} \in \mathbb{Z}\backslash\{0\}$? 
			\\ \\ 
			Because the smallest positive integer is 1, the smallest integer perturbation is in fact 1 
			
			\newpage
			
			\item What is the smallest (in magnitude) IEEE 754-1985 64-bit floating point $\mathbb{F}_{64}$ perturbation $\epsilon_{\mathbb{F}_{64}} \in \mathbb{F}_{64}\backslash\{0\}$? 
			\\ \\
			For IEEE 754-1985 64-bit, the format is $ sc_{10}c_9...c_0m_{51}m_{50}...m_0$.  We can use the formula 
			\begin{align*}
			r = (-1)^s2^{c - 1023}(1 + f) && c = \sum_{n = 0}^{10}c_n2^n, f = \sum_{k = 0}^{51}\frac{m_k}{2^{52-k}}
			\end{align*}
			So we get $c = 0$ and $f = 2^{-52}$
			\\ \\
			Which means that the exponent is $2^{-1023}$ and the gap is $(2^{-1023})(2^{-52})$, the relative gap $\epsilon_{\mathbb{F}_{64}} = 2^{-52} = 2.22044604925031 * 10^{-16}$		
			\\ \\ \\ \\
			
			\item What is the smallest (in magnitude) IEEE 754-1985 128-bit floating point $\mathbb{F}_{128}$ perturbation $\epsilon_{\mathbb{F}_{128}} \in \mathbb{F}_{128}\backslash\{0\}$?
			\\ \\
			For IEEE 754-1985 128-bit, the format is $ sc_{14}c_{13}...c_0m_{111}m_{110}...m_0$.  We can use the formula 
			\begin{align*}
			r = (-1)^s 2^{c - 16383}(1 + f) && c = \sum_{n = 0}^{14}c_n2^n, f = \sum_{k = 0}^{111}\frac{m_k}{2^{112-k}}
			\end{align*}
			So we get $c = 0$ and $f = 2^{-112}$
			\\ \\
			Which means that the exponent is $2^{-16383}$ and the gap is $(2^{-16383})(2^{-112})$, the relative gap $\epsilon_{\mathbb{F}_{128}} = 2^{-112} = 1.92592994438724 * 10^{-34}$		
			\\ \\ \\ \\
			\text{Link: }\url{https://en.wikipedia.org/wiki/IEEE_754} (clickable link)
		\end{enumerate}
	
		\newpage
		\item 
		\begin{enumerate}[label = (\roman*)]
			\item 
			For the specific function $f(x) = 
			\begin{cases}
				-55 & x < 0.5 \\
				55 & x \geq 0.5
			\end{cases}$ where $x \in \mathbb{R}$ is a \textbf{real variable} in the interval $[0,1]$, what is the relative condition number $\kappa(x)$, for all values of $x$?  (i.e. as a function of x)
			\begin{align*}
				\kappa(x) &= \sup \limits_{\delta x} \left[\left.\frac{||\delta f||}{||f(x) ||} \right/ \frac{||\delta x||}{||x||}\right] \\
				&= \sup \limits_{\delta x} \left[\left.\frac{110}{55} \right/ \frac{||\delta x||}{||x||}\right] \\
				&= \sup \limits_{\delta x} \frac{2||x||}{|| \delta x ||} \\
				&= DNE
			\end{align*}
			\\ \\ \\
			\item 
			For the specific function $f(x) = 
			\begin{cases}
				-55 & x < 0.5 \\
				55 & x \geq 0.5
			\end{cases}$ where $x \in \mathbb{F}_{64}$ is a \textbf{64-bit floating point variable} in the interval $[0,1]$, what is the relative condition number $\kappa(x)$, for all values of $x$?  (i.e. as a function of x)
			\begin{align*}
				\kappa(x) &= \sup \limits_{\delta x} \left[\left.\frac{||\delta f||}{||f(x) ||} \right/ \frac{||\delta x||}{||x||}\right] \\
				&= \sup \limits_{\delta x} \left[\left.\frac{110}{55} \right/ \frac{||\delta x||}{||x||}\right] \\
				&= \sup \limits_{\delta x} \frac{2||x||}{|| \delta x ||} \\
				&= \frac{2|x|}{2^{-52} } \\
				&= \frac{|x|}{2^{-53}}
			\end{align*}
			\newpage
			\item 
			For the specific function $f(x) = 
			\begin{cases}
				-55 & x \leq 9, 989, 224 \\
				55 & x \geq 9, 989, 225 \\
			\end{cases}$ where $x \in \mathbb{Z}$ is an \textbf{integer variable}, what is the relative condition number $\kappa(x)$, for all values of $x$?  (i.e. as a function of x)
			\begin{align*}
				\kappa(x) &= \sup \limits_{\delta x} \left[\left.\frac{||\delta f||}{||f(x) ||} \right/ \frac{||\delta x||}{||x||}\right] \\
				&= \sup \limits_{\delta x} \left[\left.\frac{110}{55} \right/ \frac{||\delta x||}{||x||}\right] \\
				&= \sup \limits_{\delta x} \frac{2||x||}{|| \delta x ||} \\
				&= \frac{2||x||}{1} \\ 
				&= 2|x|
			\end{align*}
			
	\end{enumerate}
	\end{enumerate}
\newpage
\noindent \textbf{Problem 2: }Derive the matrix least squares problem for fitting a
data set $\{y(t_i),t_i\}_{i = 1,..,m}$ by
	\begin{enumerate}[label = (\alph*)]
		\item a constant \\ \\
		Notice: a constant is $y(t_i) = c = y_i$
		$$
		\begin{bmatrix}
			1 \\
			\vdots \\
			1
		\end{bmatrix}
		\begin{bmatrix}
			c
		\end{bmatrix}
		= 
		\begin{bmatrix}
			y_1 \\
			\vdots \\
			y_m
		\end{bmatrix}
		$$
		\item a straight line $z(t) = a + bt$ \\ \\
		Notice: a straight line is $y(t_i) = a + bt_i = y_i$
		$$
		\begin{bmatrix}
			1 & t_1 \\
			\vdots & \vdots \\
			1 & t_m
		\end{bmatrix}
		\begin{bmatrix}
			a \\
			b
		\end{bmatrix}
		=
		\begin{bmatrix}
			y_1 \\
			\vdots \\
			y_m
		\end{bmatrix}
		$$
		\item What is the solution in part (a)? \\ \\
		Solving using the formula: $A^*A\vec{c} = A^*\vec{y} $
		$$
		\begin{bmatrix}
		1 & \dotsb & 1
		\end{bmatrix}
		\begin{bmatrix}
		1 \\
		\vdots \\
		1
		\end{bmatrix}
		\begin{bmatrix}
		c
		\end{bmatrix}
		= 
		\begin{bmatrix}
		1 & \dotsb & 1	
		\end{bmatrix}
		\begin{bmatrix}
		y_1 \\
		\vdots \\
		y_m
		\end{bmatrix}
		$$
		\begin{align*}
		mc &= y_1 + \dotsb + y_m \\
		c &= \frac{y_1 + \dotsb + y_m}{m}
		\end{align*}
		Notice this is the average of the y values of the points given, which makes sense because the least squares fit should be a line that goes through a majority of the points. 
		\newpage
		\item Explain why, in general, solving the least squares problem using the
		normal equations is not such a good idea. \\ \\
		The problem with solving the least squares problem using normal equations is that it is unstable when $\kappa(A)$ is not uniformly bounded. 
		\\ \\
		\item  Suggest one alternative approach, what are its advantages and disadvantages?
		\\ \\
		SVD is an alternative approach. Advantages to it is that it is stable for full rank matrices, where normal equaltions is unstable.  A disadvantage to it is that it is the most expensive however between all the other methods. 
		\\ \\
		\item \textbf{Part (ii.): }Identify period of exponential growth (a period where the growth looks linear on the log scale) \\ \\
		The graph looks linear from 39 days to 70 days after 1/22. 
		\\ \\
		Specified Date Range: \{ 3/1/20 - 4/1/20 \} 
		\\ \\
		\textbf{Part (iv): }Use the model to extrapolate 7 days (add to the plot); what is the count?
		$$
		\begin{Bmatrix}
			140,427 \\
			169,617 \\
			204,874 \\
			247,461 \\
			298,900 \\
			361,031 \\
			436,077
		\end{Bmatrix}
		$$
	\end{enumerate}
\newpage
\noindent \textbf{Problem 3: }Let $f(x)$ denote the exact solution to the exact problem, let $\tilde{f}(x)$ denote the solution computed by an algorithm 
	\begin{enumerate}[label = (\alph*)]
		\item Complete the statement, "We say that an algorithm $\tilde{f}$ for a problem $f(x)$ \textit{is} stable \textit{if for each} $x \in X$"
		$$
		\frac{|| \tilde{f}(x) - f(\tilde{x}) ||}{||f(\tilde{x} )||} = \mathcal{O}(\epsilon_{mach}) 
		$$
		for some $\tilde{x}$ with 
		$$
		\frac{|| \tilde{x} - x ||}{|| x ||} = \mathcal{O}(\epsilon_{mach}) 
		$$
		\\ \\
		\item Complete the statement, "We say that an algorithm $\tilde{f}$ for a problem $f(x)$ \textit{is} backward stable \textit{if for each} $x \in X$"
		$$
		\tilde{f}(x) = f(\tilde{x})
		$$
		for some $\tilde{x}$ with 
		$$
		\frac{|| \tilde{x} - x ||}{|| x ||} = \mathcal{O}(\epsilon_{mach}) 
		$$
		\newpage
		\item Show that the obvious algorithm for solving (for $x$) the 1-by-1 system $rx = b$ is backward stable if executed in matlab on a modern-day computer. Explain your notation and any results / definitions / axioms you are invoking.
		\\ \\
		Let 
		\begin{align*}
			f(x) = rx = b &&& \tilde{f}(x) = rx(1 + \epsilon) = b &&& f(\tilde{x}) = r(x(1 + \epsilon)) = b \\
			x = \frac{b}{r} &&& x = \frac{b}{r(1+\epsilon)} &&& x = \frac{b}{r(1+\epsilon)}
		\end{align*}
		Thus for $f(x) = b$, because $\tilde{f}(x) = f(\tilde{x})$ with $\frac{|| \tilde{x} - x ||}{|| x ||} = \mathcal{O}(\epsilon_{mach})$, the algorithm to solve this which is division is backwards stable
		\\ \\ 
		\item Explain how backward stability, the condition number, and the available “computational precision” limit how well we can solve a problem numerically. (You may state a theorem, but it is not necessary (but highly recommended)).
		\\ \\
			With backwards stablity, condition numbers, and the available “computational precision”, it limits how well we can solve a problem numerically.  Because a computer can not calculate an exact smallest number or an exact greatest number, there will always be round-off errors that will give the slightest change in our answers.  Because of this as well, we always have to consider the $\delta$ in all out solutions such that $(1 + 0) \not = (1 + 0)$ when computing as $(1 + 0) = (1 + 0)(1 + \epsilon)$. As well, with these limitations, we sometimes get instability which can lead to very bad results. 
	\end{enumerate}
\newpage
\noindent \textbf{Problem 4: } The sloped line is most likely a least squares fit (of some kind). Do you have any
comments? 
\\ \\
We see that from the least square fit that the approximate line most likely seems to hit the majority of the points given, and almost completely ignores the few outliers.  This might be because of the two bigger outliers, NYSE and Deutsche Börse, seem to cancel each other out as they're both approximately equidistant to the line.  The line also tells these companies how they are doing in retrospect to the other companies, almost like an 'average' line.

\end{document}
